---
title: "MultiAmplicon - a real world example"
author: "Emanuel Heitlinger"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Data preparation (download and filtering)

We first
[download the sample data](https://svalbard.biologie.hu-berlin.de:443/d/c291b870178f4abc8c59/)
set from consisting of 192 fastq file-pairs from 18S and 16S amplicon
sequencing of fecess and intestinal contents of carnivores (hyenas and
wolfes). The help file for the
[`carnivoreSeqRuns`](https://derele.github.io/MultiAmplicon/reference/carnivoreSeqRuns.html)
(containing sample data included in the package), shows how this data
has been downloaded from
[NCBI-SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA386767).

Now we can run our standard workflow. But as usual with real data we
have to filter the input files first. This particular sequencing was
of quite low quality, so we have to trim and screen quite harshly.

```{r filter, message=FALSE}
library(MultiAmplicon)

path <- "~/download" ## change according to where you downloaded

fastqFiles <- list.files(path, pattern=".fastq.gz$", full.names=TRUE)

fastqF <- grep("_1.fastq.gz", fastqFiles, value = TRUE)
fastqR <- grep("_2.fastq.gz", fastqFiles, value = TRUE)

samples <- gsub("_1.fastq\\.gz", "\\1", basename(fastqF))

filt_path <- "./filtered"
if(!file_test("-d", filt_path)) dir.create(filt_path)

filtFs <- file.path(filt_path, paste0(samples, "_F_filt.fastq.gz"))
names(filtFs) <- samples
filtRs <- file.path(filt_path, paste0(samples, "_R_filt.fastq.gz"))
names(filtRs) <- samples

## some files will be filtered out completely, therefore allowing 50
## files less present and still don't redo filtering
if(sum(file.exists(fastqF)) -
   sum(file.exists(filtFs)) > 50){
    lapply(seq_along(fastqF),  function (i) {
        filterAndTrim(fastqF[i], filtFs[i], fastqR[i], filtRs[i],
                      truncLen=c(170,170), minLen=c(170,170), 
                      maxN=0, maxEE=2, truncQ=2, 
                      compress=TRUE, verbose=TRUE)
    })
}

names(filtFs) <- names(filtRs) <- samples

files <- PairedReadFileSet(filtFs, filtRs)
```

## Data preparation (primer set)

Now we have our sequencing read input data, only the primers are still
missing. The primer set for the above is included in the MultiAmplicon
package.

```{r prepPrimers, cache=TRUE}
primer.file <- system.file("extdata", "real_world_primers.csv",
                           package = "MultiAmplicon")

ptable <- read.csv(primer.file, sep=",", header=TRUE, stringsAsFactors=FALSE)

primerF <- ptable[, "TS.SequenceF"]
primerR <- ptable[, "TS.SequenceR"]

names(primerF) <- as.character(ptable[, "corrected.NameF"])
names(primerR) <- as.character(ptable[, "corrected.NameR"])

primers <- PrimerPairsSet(primerF, primerR)
```

## Running the MultiAmplicon pipeline
